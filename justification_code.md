# Justification par le Code - MSPR TPTE502

## 1. D√©velopper des composants d'acc√®s aux donn√©es SQL et NoSQL

**Justification** : L'application A'rosa-je d√©montre une ma√Ætrise avanc√©e des composants d'acc√®s aux donn√©es gr√¢ce √† une architecture hybride SQL/NoSQL. SQLAlchemy est utilis√© pour la persistance structur√©e, tandis que Redis apporte performance et r√©activit√© pour les donn√©es volatiles. Cette approche optimise les performances tout en maintenant l'int√©grit√© des donn√©es, essentielle pour une application de gestion de plantes o√π les donn√©es doivent √™tre √† la fois persistantes et rapidement accessibles.

### SQLAlchemy (SQL)
```python
# api/utils/database.py - Configuration SQLAlchemy optimis√©e
Base = declarative_base()
engine = create_engine(f"sqlite:///{DB_PATH}")
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# api/models/photo.py - Mod√®le avec relations et contraintes
class Photo(Base):
    __tablename__ = "photos"
    id = Column(Integer, primary_key=True, index=True)
    filename = Column(String, nullable=False)
    url = Column(String, nullable=False)
    description = Column(String, nullable=True)
    type = Column(String, nullable=False)  # 'plant', 'garde_start', 'garde_end'
    plant_id = Column(Integer, ForeignKey("plants.id"))
    plant = relationship("Plant", back_populates="photos")
```

### Redis (NoSQL)
```python
# api/crud/photo.py - Utilisation avanc√©e du cache Redis
def get_plant_photos(self, db: Session, plant_id: int) -> Dict[str, List[PhotoResponse]]:
    # V√©rifier le cache Redis
    cache_key = f"plant_photos:{plant_id}"
    cached_photos = self.redis_client.get(cache_key)
    
    if cached_photos:
        return {"photos": json.loads(cached_photos)}
        
    # Si pas en cache, r√©cup√©rer depuis la base de donn√©es
    photos = db.query(Photo).filter(Photo.plant_id == plant_id).all()
    
    # Convertir et mettre en cache
    photos_data = [PhotoResponse(...).model_dump(mode='json') for photo in photos]
    self.redis_client.setex(cache_key, self.cache_ttl, json.dumps(photos_data))
    
    return {"photos": photos_data}
```

## 2. D√©velopper des composants dans le langage d'une base de donn√©es

**Justification** : L'application exploite pleinement les capacit√©s avanc√©es de SQLAlchemy ORM pour mod√©liser des relations complexes et des contraintes m√©tier. Les migrations Alembic assurent l'√©volution coh√©rente du sch√©ma. Cette impl√©mentation respecte les principes de normalisation et d'int√©grit√© r√©f√©rentielle tout en facilitant l'√©volution de la base de donn√©es, un facteur cl√© pour la maintenabilit√© √† long terme de l'application.

### Mod√®les et Relations Complexes
```python
# api/models/message.py - Relations multiples avec cascades
class Conversation(Base):
    __tablename__ = "conversations"
    id = Column(Integer, primary_key=True, index=True)
    type = Column(Enum(ConversationType))
    related_id = Column(Integer, nullable=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

    # Relations avec comportements de cascade
    messages = relationship("Message", back_populates="conversation", cascade="all, delete-orphan")
    participants = relationship("ConversationParticipant", back_populates="conversation", cascade="all, delete-orphan")
    plant_care = relationship("PlantCare", back_populates="conversation", uselist=False)
    typing_users = relationship("UserTypingStatus", back_populates="conversation", cascade="all, delete-orphan")
```

### Migrations et Gestion du Sch√©ma
```python
# api/alembic/env.py - Configuration avanc√©e des migrations
from alembic import context
from utils.database import Base
from models import user, plant, advice, photo, plant_care

# Import automatique des mod√®les pour la d√©tection des changements
target_metadata = Base.metadata

def run_migrations_online():
    with connectable.connect() as connection:
        context.configure(
            connection=connection,
            target_metadata=target_metadata,
            compare_type=True  # Compare les types pour d√©tecter les changements
        )
        with context.begin_transaction():
            context.run_migrations()
```

## 3. D√©finir l'architecture logicielle d'une application

**Justification** : L'architecture microservices adopt√©e d√©montre une vision orient√©e √©volutivit√© et maintenabilit√©. Chaque service (API, Web, Mobile, Redis) est conteneuris√© et encapsul√©, avec une s√©paration claire des responsabilit√©s et des interfaces bien d√©finies. Les services de sant√© (healthchecks) et les d√©pendances explicites assurent la robustesse et la r√©silience du syst√®me, essentielles pour une application qui doit √™tre toujours disponible pour les utilisateurs.

### Architecture Microservices Optimis√©e
```yaml
# docker-compose.yml - Architecture compl√®te avec d√©pendances et healthchecks
services:
  api:
    container_name: arosa-je-api
    image: arosa-je-api
    volumes:
      - ./api:/app
      - ./api/assets/database:/app/assets/database
      - ./api/assets/img:/app/assets/img
    depends_on:
      api-redis:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 10s
      retries: 3

  web:
    container_name: arosa-je-web
    depends_on:
      - api
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:3000" ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  api-redis:
    image: redis:7-alpine
    container_name: arosa-je-api-redis
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
```

### API Structur√©e avec S√©paration des Pr√©occupations
```python
# api/main.py - Structure modulaire de l'API
app = FastAPI(title=PROJECT_NAME, version=VERSION)

# Middleware de s√©curit√© et performance
app.add_middleware(
    CORSMiddleware,
    allow_origins=CORS_ALLOW_ORIGINS,
    allow_credentials=True,
    allow_methods=CORS_ALLOW_METHODS,
    allow_headers=CORS_ALLOW_HEADERS
)

# Routers avec s√©paration des pr√©occupations
app.include_router(auth.router)
app.include_router(plant.router)
app.include_router(monitoring.router, prefix="/monitoring", tags=["monitoring"])

# Point de sant√© pour les healthchecks
@app.get("/health", tags=["monitoring"])
async def health_check():
    return {"status": "healthy"}
```

## 4. D√©velopper des composants m√©tiers

**Justification** : La conception des composants m√©tiers suit le principe de responsabilit√© unique avec un CRUD g√©n√©rique r√©utilisable et des impl√©mentations sp√©cifiques pour les cas particuliers. L'utilisation de types g√©n√©riques et de mod√®les Pydantic assure la coh√©rence et la validation des donn√©es √† tous les niveaux. Cette approche r√©duit la duplication de code et facilite l'√©volution des fonctionnalit√©s m√©tier, un avantage crucial pour une application en constante √©volution.

### CRUD G√©n√©rique avec Types Param√©tr√©s
```python
# api/crud/base.py - CRUD g√©n√©rique avec types g√©n√©riques
class CRUDBase(Generic[ModelType, CreateSchemaType, UpdateSchemaType]):
    def __init__(self, model: Type[ModelType]):
        self.model = model

    def get(self, db: Session, id: int) -> Optional[ModelType]:
        """R√©cup√©rer un √©l√©ment par son ID"""
        return db.query(self.model).filter(self.model.id == id).first()

    def get_multi(
        self, 
        db: Session, 
        *, 
        skip: int = 0, 
        limit: int = 100,
        filters: Dict[str, Any] = None
    ) -> List[ModelType]:
        """R√©cup√©rer plusieurs √©l√©ments avec pagination et filtres dynamiques"""
        query = db.query(self.model)
        
        if filters:
            for key, value in filters.items():
                if hasattr(self.model, key):
                    query = query.filter(getattr(self.model, key) == value)
                    
        return query.offset(skip).limit(limit).all()
```

### Logique M√©tier Sp√©cifique
```python
# api/crud/photo.py - CRUD sp√©cialis√© avec logique m√©tier sp√©cifique
class CRUDPhoto(CRUDBase[Photo, PhotoCreate, PhotoCreate]):
    def delete_with_file(self, db: Session, *, id: int) -> bool:
        """Supprime une photo, son fichier et invalide le cache"""
        photo = self.get(db=db, id=id)
        if photo:
            # Invalider le cache
            self.redis_client.delete(f"plant_photos:{photo.plant_id}")
            
            # Supprimer le fichier physique
            ImageHandler.delete_image(photo.filename)
            
            # Supprimer l'entr√©e en base
            db.delete(photo)
            db.commit()
            return True
        return False
```

## 5. Pr√©parer et ex√©cuter les plans de tests d'une application

**Justification** : L'application int√®gre une strat√©gie de test compl√®te avec des tests d'int√©gration automatis√©s utilisant Tavern pour valider les workflows complets. Le monitoring des performances permet d'identifier proactivement les probl√®mes potentiels. Cette approche exhaustive garantit la fiabilit√© du syst√®me et la rapidit√© de d√©tection des anomalies, deux aspects essentiels pour une application critique manipulant des donn√©es sensibles comme les plantes des utilisateurs.

### Tests d'Int√©gration de Workflow Complet
```yaml
# api/tests/workflows/test_auth_workflow.tavern.yaml - Test complet d'authentification
test_name: Test authentification
marks:
  - usefixtures:
      - api_url
      - test_user_email
      - test_password

stages:
  - name: Test inscription utilisateur
    request:
      url: "{api_url}/auth/register"
      method: POST
      json:
        nom: "Dupont"
        prenom: "Jean"
        email: "{test_user_email}"
        telephone: "0612345678"
        localisation: "Paris"
        password: "{test_password}"
    response:
      status_code: 200
      save:
        json:
          saved_email: email

  - name: Test login
    request:
      url: "{api_url}/auth/login"
      method: POST
      headers:
        content-type: application/x-www-form-urlencoded
      data:
        username: "{saved_email}"
        password: "{test_password}"
    response:
      status_code: 200
      save:
        json:
          auth_token: access_token
```

### Monitoring Avanc√© des Performances
```python
# api/routers/monitoring.py - Monitoring s√©curis√© des performances
from fastapi import APIRouter, Depends
from utils.monitoring import get_monitoring_stats
from utils.security import get_current_user

router = APIRouter(
    prefix="/monitoring",
    tags=["monitoring"],
    dependencies=[Depends(get_current_user)]  # S√©curiser l'acc√®s aux m√©triques
)

@router.get("/stats")
async def get_stats():
    """R√©cup√®re les statistiques de monitoring de l'API"""
    return get_monitoring_stats()
```

## 6. Pr√©parer et ex√©cuter le d√©ploiement d'une application

**Justification** : Le d√©ploiement est enti√®rement automatis√© gr√¢ce √† Docker et des scripts d'initialisation robustes. Les builds multi-stage optimisent la taille des images et r√©duisent les vuln√©rabilit√©s potentielles. Les scripts d'initialisation garantissent une configuration coh√©rente de l'environnement, un aspect crucial pour √©viter les probl√®mes de d√©ploiement et permettre une mise en production fiable et r√©p√©table.

### Docker Multi-stage pour Optimisation des Images
```dockerfile
# api/Dockerfile - Build multi-stage optimis√© et s√©curis√©
FROM python:3.11-alpine as builder

WORKDIR /app

# Installation des d√©pendances de build
RUN apk add --no-cache gcc musl-dev libffi-dev

# Installation des d√©pendances Python
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Stage final avec image minimale
FROM python:3.11-alpine

WORKDIR /app

# Copie uniquement des d√©pendances n√©cessaires
COPY --from=builder /usr/local/lib/python3.11/site-packages/ /usr/local/lib/python3.11/site-packages/
COPY --from=builder /usr/local/bin/ /usr/local/bin/

# Installation des d√©pendances minimales
RUN apk add --no-cache sqlite curl

# Optimisation des workers Uvicorn
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "2", "--limit-concurrency", "50"]
```

### Scripts d'Initialisation et D√©ploiement
```bash
# bin/up - Script de d√©ploiement avec gestion des erreurs
cleanup() {
    echo -e "\n\nüõë Arr√™t des conteneurs..."
    
    # Arr√™ter l'√©mulateur Android s'il est en cours d'ex√©cution
    stop_android_emulator
    
    if [ "$1" = "all" ]; then
        docker-compose down
        echo "‚úÖ Tous les services ont √©t√© arr√™t√©s."
    else
        # Convertir les arguments en array pour g√©rer plusieurs services
        local services=($@)
        if [ ${#services[@]} -gt 0 ]; then
            # S'assurer que Redis est arr√™t√© si l'API est arr√™t√©e
            if [[ " ${services[@]} " =~ " api " ]]; then
                docker-compose stop api-redis api "${services[@]}"
            else
                docker-compose stop "${services[@]}"
            fi
            # V√©rifier si les ports sont toujours utilis√©s
            for service in "${services[@]}"; do
                # [...code de v√©rification des ports...]
            done
            echo "‚úÖ Services arr√™t√©s : ${services[*]}"
        fi
    fi
}
```

## 7. Documenter le d√©ploiement d'une application

**Justification** : La documentation est exceptionnellement compl√®te, couvrant tous les aspects de l'installation, de la configuration et du d√©ploiement. Les instructions d√©taill√©es, les scripts utilitaires et les solutions de d√©pannage assurent une exp√©rience fluide pour les d√©veloppeurs et les op√©rateurs. Cette approche exemplaire de la documentation garantit que l'application peut √™tre maintenue et d√©ploy√©e par diff√©rentes √©quipes, un atout majeur pour la continuit√© du projet.

### Documentation Technique Exhaustive
```markdown
# README.md - Documentation d√©taill√©e du d√©ploiement
## üì¶ Installation et D√©ploiement

### **Pr√©requis**
- Docker & Docker Compose
- Git
- Python 3.11+ (pour l'API)

### **√âtapes d'installation**
```bash
# Cloner le d√©p√¥t
git clone <repository-url>

# Rendre les scripts ex√©cutables
chmod +x bin/up bin/update bin/setup-api bin/setup-env

# Configurer les variables d'environnement
bin/setup-env

# Configurer l'environnement Python pour l'API
bin/setup-api

# D√©marrer tous les services
bin/up all
```

### **üõ†Ô∏è Commandes Utiles**
```bash
# S'attacher √† un conteneur sp√©cifique pour le debug
docker attach arosa-je-api    # Pour d√©bugger l'API
docker attach arosa-je-web    # Pour d√©bugger le frontend

# Note: Utilisez CTRL+P CTRL+Q pour se d√©tacher sans arr√™ter le conteneur
```

### **‚ö†Ô∏è R√©solution des Probl√®mes**
Si `bin/up all` √©choue, v√©rifiez :
1. Que Docker est en cours d'ex√©cution
2. Que les ports requis (8000, 3000, 5000) sont disponibles
```

## 8. Justifier le choix d'un protocole d'authentification

**Justification** : L'impl√©mentation de JWT (JSON Web Tokens) avec une configuration CORS rigoureuse d√©montre une compr√©hension approfondie des enjeux de s√©curit√© modernes. Les tokens √† dur√©e limit√©e, la gestion s√©curis√©e des identifiants et la validation stricte des origines CORS permettent d'assurer une authentification robuste et une protection contre les attaques CSRF et XSS, cruciales pour prot√©ger les donn√©es sensibles des utilisateurs.

### JWT S√©curis√© avec Expiration Contr√¥l√©e
```python
# api/utils/security.py - Impl√©mentation JWT compl√®te
def create_access_token(data: dict, expires_delta: Optional[timedelta] = None) -> str:
    """Cr√©e un token JWT s√©curis√© avec expiration"""
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt

async def get_current_user(
    db: Session = Depends(get_db),
    token: str = Depends(oauth2_scheme)
) -> Optional[dict]:
    """R√©cup√®re et valide l'utilisateur √† partir du token JWT"""
    credentials_exception = HTTPException(
        status_code=401,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )
    
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        user_id: str = payload.get("sub")
        if user_id is None:
            raise credentials_exception
        token_data = TokenData(user_id=user_id)
    except JWTError:
        raise credentials_exception
    
    user = user_crud.get(db, id=int(token_data.user_id))
    if user is None:
        raise credentials_exception
    return user
```

### CORS Configur√© pour la S√©curit√©
```python
# api/utils/settings.py - Configuration CORS stricte
# Configuration CORS
CORS_ALLOW_ORIGINS = os.getenv("CORS_ORIGINS", "http://localhost:3000,http://web:3000").split(",")
CORS_ALLOW_METHODS = ["GET", "POST", "PUT", "DELETE", "OPTIONS", "PATCH"]
CORS_ALLOW_HEADERS = [
    "Content-Type",
    "Authorization",
    "Accept",
    "Origin",
    "X-Requested-With",
    "Access-Control-Request-Method",
    "Access-Control-Request-Headers"
]
```

## 9. Optimiser configuration d'une mise en container d'une solution

**Justification** : La containerisation est exemplaire avec une optimisation fine des images Docker, des healthchecks complets et une gestion efficace des ressources. Les volumes persistants, les variables d'environnement externalis√©es et les r√©seaux d√©di√©s d√©montrent une ma√Ætrise avanc√©e des meilleures pratiques Docker. Cette configuration assure une haute disponibilit√©, une isolation de s√©curit√© et des performances optimales, essentielles pour une application critique en production.

### Configuration Docker Optimis√©e et R√©siliente
```yaml
# docker-compose.yml - Configuration Docker compl√®te avec r√©seaux et volumes
services:
  api:
    container_name: arosa-je-api
    volumes:
      - ./api:/app
      - ./api/assets/database:/app/assets/database
      - ./api/assets/img:/app/assets/img
    environment:
      - PYTHONUNBUFFERED=1
      - GIT_DISCOVERY_ACROSS_FILESYSTEM=1
    networks:
      - arosa-je-network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 10s
      timeout: 5s
      retries: 3
  
  api-redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
      - ./redis/users.acl:/data/users.acl:ro
    command: >
      sh -c '
        redis-server --appendonly yes --requirepass "$${REDIS_PASSWORD}" --aclfile /data/users.acl'
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]

networks:
  arosa-je-network:
    name: arosa-je-network

volumes:
  redis_data:
```

### Gestion Fine des Ressources et Sant√© des Conteneurs
```dockerfile
# web/Dockerfile - Optimisation des ressources et healthcheck
ENV NODE_OPTIONS='--no-warnings --max-old-space-size=512'
RUN npm install -g nuxt cross-env

# Nettoyage du cache npm pour r√©duire la taille de l'image
RUN npm cache clean --force

# Healthcheck pour surveillance proactive
HEALTHCHECK --interval=30s --timeout=5s --start-period=10s --retries=3 \
    CMD curl -f http://localhost:3000/ || exit 1
``` 